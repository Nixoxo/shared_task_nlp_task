{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp_en = spacy.load('en')\n",
    "nlp_de = spacy.load('de')\n",
    "from spacy.en import English\n",
    "parser = English()\n",
    "import xml.etree.ElementTree as ET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy.en import English\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_file_csv = \"textProcessing_testKaldi.csv\"\n",
    "test_data = None\n",
    "with open(test_file_csv, 'r') as reader:\n",
    "    test_data = reader.readlines()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prompt_map_test_data():\n",
    "    prompt_map = {}\n",
    "    for item in test_data[1:]:\n",
    "        split = item.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "        prompt = split[1]\n",
    "        \n",
    "        if prompt in prompt_map:\n",
    "            prompt_map[prompt].append({'id': split[0], \"transcript\": split[3]})\n",
    "        else:\n",
    "            arr = []\n",
    "            arr.append({'id':split[0], \"transcript\":split[3]})\n",
    "            prompt_map[prompt] = arr\n",
    "            \n",
    "    return prompt_map\n",
    "prompt_test_map = prompt_map_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERENE GRAMMAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_prompt_response_map(gram):\n",
    "    prompt_response_map = {}\n",
    "    for prompt_unit in gram:\n",
    "        key = None\n",
    "        responses = []\n",
    "        for prompt in prompt_unit:\n",
    "            if prompt.tag == None:\n",
    "                print(\"None\")\n",
    "            else:\n",
    "                if(prompt.tag == 'prompt'):\n",
    "                    key = prompt.text\n",
    "                elif(prompt.tag == 'response'):\n",
    "                    responses.append(prompt.text)\n",
    "        prompt_response_map[key] = responses\n",
    "    return prompt_response_map\n",
    "\n",
    "def read_grammar_and_create_map(file):\n",
    "    tree = ET.parse(file)\n",
    "    grammar = tree.getroot()\n",
    "    return create_prompt_response_map(grammar)\n",
    "    \n",
    "prompt_response_map = read_grammar_and_create_map('referenceGrammar.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sag_prompts(prompt_response_map):\n",
    "    sag_prompts = {}\n",
    "    for key in prompt_response_map:\n",
    "        if \"Sag\" in key:\n",
    "            sag_prompts[key] = prompt_response_map[key]\n",
    "    return sag_prompts\n",
    "sag_prompts = get_sag_prompts(prompt_response_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nlp_sentence(sentence):\n",
    "    parsed = parser(sentence)\n",
    "    lemmas = []\n",
    "    words = []\n",
    "    tags = []\n",
    "    poss = []\n",
    "    for i, token in enumerate(parsed):\n",
    "        lemma = token.lemma_\n",
    "        words.append(token)\n",
    "        lemmas.append(lemma)\n",
    "        tag = token.tag_\n",
    "        pos = token.tag_\n",
    "        tags.append(tag)\n",
    "        poss.append(pos)\n",
    "    return words, lemmas, tags, poss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "sentences = sag_prompts['Sag: Ich habe keine Reservation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# special case he she it ber체cksichtigen mit s anh채ngen\n",
    "def extract_verb_chunk(sentence):\n",
    "    words, lemmas, tags, poss = nlp_sentence(sentence)\n",
    "    verbs_poss = []\n",
    "    verb_pos = None\n",
    "    words_poss = []\n",
    "    word_pos = None\n",
    "    for index in range(0, len(words)):\n",
    "        tag = tags[index]\n",
    "        word = words[index]\n",
    "        \n",
    "        if tag == 'VBP':\n",
    "            if verb_pos == None and word_pos == None:\n",
    "                verb_pos = []\n",
    "                word_pos = []\n",
    "            verb_pos.append(tag)\n",
    "            word_pos.append(word)\n",
    "        elif tag == 'NN' or tag == 'NNS':\n",
    "            verbs_poss.append(verb_pos)\n",
    "            words_poss.append(word_pos)\n",
    "            verb_pos = []\n",
    "            word_pos = []\n",
    "        else:\n",
    "            #print(str(word) + \"\\t\" + str(tag))\n",
    "            if verb_pos == None and word_pos == None:\n",
    "                continue\n",
    "            verb_pos.append(tag)\n",
    "            word_pos.append(word) \n",
    "    if len(verb_pos) > 0:\n",
    "        verbs_poss.append(verb_pos)\n",
    "        words_poss.append(word_pos)\n",
    "    return verbs_poss, words_poss\n",
    "            \n",
    "def extract_verb(poss, words):\n",
    "    one_verb = 0\n",
    "    verb = None\n",
    "    index = None\n",
    "    #for item in range(0, )\n",
    "    for i in range(0, len(poss)):\n",
    "        if poss[i] =='VBP':\n",
    "            one_verb += 1\n",
    "            index = i\n",
    "    \n",
    "    if one_verb == 1 and index != None:\n",
    "        return words[index]\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['VBP', 'RB']], [[do, not]])\n"
     ]
    }
   ],
   "source": [
    "sent = \"i do not\"\n",
    "print(extract_verb_chunk(sent))\n",
    "#print(nlp_sentence(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "verbs = []\n",
    "words = []\n",
    "dict_verb = []\n",
    "for sentence in sentences:\n",
    "    #_, lemmas, tags, poss = nlp_sentence(sentence)\n",
    "    #print(\"%s \\t %s\" %(sentence, tags))\n",
    "    verb, word = extract_verb_chunk(sentence)\n",
    "    if len(verb)  !=  1 or len(word) != 1: \n",
    "        print(\"emergency\")\n",
    "    words.append(word[0])\n",
    "    verbs.append(verb[0])\n",
    "    #print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do\n",
      "do\n",
      "do\n",
      "do\n",
      "do\n",
      "do\n",
      "do\n",
      "do\n",
      "do\n",
      "do\n",
      "do\n",
      "do\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(verbs)):\n",
    "    print(extract_verb(verbs[0], words[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VBP', 'RB']\n",
      "['VBP', 'RB', 'VB', 'DT']\n",
      "['VBP', 'RB']\n",
      "['VBP', 'RB', 'VB', 'DT']\n",
      "['VBP', 'RB']\n",
      "['VBP', 'RB', 'VB', 'DT']\n",
      "['VBP', 'RB']\n",
      "['VBP', 'RB', 'VB', 'DT']\n",
      "['VBP', 'RB']\n",
      "['VBP', 'RB', 'VB', 'DT']\n",
      "['VBP', 'RB']\n",
      "['VBP', 'RB', 'VB', 'DT']\n"
     ]
    }
   ],
   "source": [
    "for verb in verbs:\n",
    "    print(verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBP\n",
      "RB\n",
      "{}\n",
      "[do, not]\n",
      "{'VBP': {}, 'RB': {}}\n",
      "______\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TODOD Diese Mapping\n",
    "verb_combination = {}\n",
    "for index in range(0, len(verbs)):\n",
    "    verb = extract_verb(verbs[index], words[index])\n",
    "    if verb in verb_combination:\n",
    "        print(verb)\n",
    "    else:\n",
    "        key = {}\n",
    "        last_key = None\n",
    "        for item in range(0, len(verbs[index])):\n",
    "            print(verbs[index][item])\n",
    "            key[verbs[index][item]] = {}\n",
    "            last_key = key[verbs[index][item]]\n",
    "            #key[item] = \n",
    "        print(last_key)\n",
    "        print(words[index])\n",
    "        print(key)\n",
    "        #verb_combination[verb] = {key:\"test\", \"word\": {words[index]}}\n",
    "        break\n",
    "    print(verb)\n",
    "print(\"______\")\n",
    "verb_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_test = {\"a\": {\"b\":{\"c\": \"Hello\"}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': {'c': 'Hello'}}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_test['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_test = {}\n",
    "dict_test['a'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_test['b'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_test['a'] = {'b':{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-154-addafdcb2428>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-154-addafdcb2428>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    dict_test['a'] = {dict_test['a'], 'c': {}}\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "dict_test['a'] = {dict_test['a'], 'c': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def insert(tree, key, value):\n",
    "    if key:\n",
    "        first, rest = key[0], key[1:]\n",
    "        if first not in tree:\n",
    "            tree[first] = {}\n",
    "        insert(tree[first], rest, value)\n",
    "    else:\n",
    "        tree['words'] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'do': {'VBP': {'RB': {'words': [do, n't], 'VB': {'DT': {'words': [do, n't, have, a]}}}}}}\n"
     ]
    }
   ],
   "source": [
    "verb_combination = {}\n",
    "for index in range(0, len(verbs[index])):\n",
    "    #verbs[index], word[index])\n",
    "    verb = extract_verb(verbs[index], words[index])\n",
    "    verb_verbs = []\n",
    "    verb_verbs.append(str(verb))\n",
    "    verb_verbs.extend(verbs[index])\n",
    "    verbs[index]\n",
    "    insert(verb_combination, verb_verbs, words[index])\n",
    "\n",
    "print(verb_combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'VB': {'DT': {'words': [do, n't, have, a]}}, 'words': [do, n't]}"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_combination['do']['VBP']['RB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i do not',\n",
       " 'i do not have a reservation',\n",
       " \"i don't\",\n",
       " \"i don't have a reservation\",\n",
       " 'no i do not',\n",
       " 'no i do not have a reservation',\n",
       " \"no i don't\",\n",
       " \"no i don't have a reservation\",\n",
       " 'sorry i do not',\n",
       " 'sorry i do not have a reservation',\n",
       " \"sorry i don't\",\n",
       " \"sorry i don't have a reservation\"]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sag_prompts['Sag: Ich habe keine Reservation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '3671', 'transcript': 'no i pay is there a reservation'}\n",
      "{'id': '3689', 'transcript': '***  ***  do not have a reservation'}\n",
      "{'id': '3769', 'transcript': '  a tomorrow at nine   '}\n",
      "{'id': '3770', 'transcript': 'i have no reservation'}\n",
      "{'id': '3771', 'transcript': 'i have a   room for have a      room   '}\n",
      "{'id': '3773', 'transcript': \"i haven't got a reservation\"}\n",
      "{'id': '3774', 'transcript': 'i have not a reservation'}\n",
      "{'id': '3776', 'transcript': \"***  i'm mamma have a reservation\"}\n",
      "{'id': '3777', 'transcript': '***  ***   a have a reservation'}\n",
      "{'id': '3779', 'transcript': 'where no i have not have i   have no'}\n",
      "{'id': '3807', 'transcript': \"no i don't have a reservation any\"}\n",
      "{'id': '3888', 'transcript': 'no i  ***  ***  have a      ***    '}\n",
      "{'id': '3986', 'transcript': \"no i don't no i do not have a reservation\"}\n",
      "{'id': '4014', 'transcript': 'i have no reservation'}\n",
      "{'id': '4015', 'transcript': \"no i don't no i do not have a reservation\"}\n",
      "{'id': '4186', 'transcript': 'no i     am good'}\n",
      "{'id': '4187', 'transcript': 'no i have no reservation'}\n",
      "{'id': '4188', 'transcript': 'no i    ***     am a reservation'}\n",
      "{'id': '4236', 'transcript': 'i   ***   have a reservation'}\n",
      "{'id': '4237', 'transcript': \"i haven't a reservation\"}\n",
      "{'id': '4238', 'transcript': \"i don't have a reservation is bern\"}\n",
      "{'id': '4239', 'transcript': \"i don't where is bern   \"}\n",
      "{'id': '4240', 'transcript': 'i have a   thursday and    '}\n",
      "{'id': '4241', 'transcript': 'i have not a reservation'}\n",
      "{'id': '4247', 'transcript': \"the i don't have a reservation i pay by is my name is    \"}\n",
      "{'id': '4387', 'transcript': 'i have not a reservation'}\n",
      "{'id': '4389', 'transcript': 'i want a reservation'}\n",
      "{'id': '4390', 'transcript': 'i do not  ***  reservation'}\n",
      "{'id': '4392', 'transcript': 'i have not a reservation'}\n",
      "{'id': '4465', 'transcript': 'i have  ***  no reservation'}\n",
      "{'id': '4185', 'transcript': \" i don't know \"}\n",
      "{'id': '4243', 'transcript': '***  row euros hotel bar '}\n",
      "{'id': '4245', 'transcript': 'you are a   room '}\n",
      "{'id': '4246', 'transcript': 'the apple pie  '}\n",
      "{'id': '4248', 'transcript': 'where is there a      like to london'}\n",
      "{'id': '4249', 'transcript': '     ***      ***  ***   ***  cirque are there a '}\n",
      "{'id': '4388', 'transcript': '***   can buy for the silver level'}\n",
      "{'id': '4394', 'transcript': 'the can i    want a   soap of the silver level'}\n",
      "{'id': '4395', 'transcript': ' do can i    got help at the silver level'}\n",
      "{'id': '4466', 'transcript': \" i don't have a   room for the silver level\"}\n"
     ]
    }
   ],
   "source": [
    "thiskey = \"Sag: Ich habe keine Reservation\"\n",
    "for item in prompt_test_map[thiskey]:\n",
    "    accept = False\n",
    "    if item['transcript'] not in prompt_response_map[thiskey]:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "with open(\"reference_grammar_test.csv\", 'w') as writer:\n",
    "    for prompt_unit in prompt_test_map:\n",
    "        for sentence in prompt_test_map[prompt_unit]:\n",
    "            if \"***\" in sentence['transcript']:\n",
    "                continue\n",
    "            if sentence['transcript'] not in prompt_response_map[prompt_unit]:\n",
    "                counter +=1\n",
    "                writer.write(prompt_unit + \"\\t\" + sentence['transcript'] + \"\\n\")\n",
    "        \n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# special case he she it ber체cksichtigen mit s anh채ngen\n",
    "def extract_prepo(sentence):\n",
    "    words, lemmas, tags, poss = nlp_sentence(sentence)\n",
    "    prepos = []\n",
    "    prepos_ =[]\n",
    "    in_found = False\n",
    "    for index in range(0, len(words)):\n",
    "        tag = tags[index]\n",
    "        word = words[index]\n",
    "        \n",
    "        if tag == 'IN':\n",
    "            in_found = True\n",
    "            prepos.append(tag)\n",
    "            prepos_.append(word)\n",
    "            #verb_pos.append(tag)\n",
    "            #word_pos.append(word)\n",
    "            \n",
    "        elif in_found:\n",
    "            if tag == 'NN' or tag == 'NNS':\n",
    "                prepos.append(tag)\n",
    "                prepos_.append(word)\n",
    "                #verbs_poss.append(verb_pos)\n",
    "                #words_poss.append(word_pos)\n",
    "                #verb_pos = []\n",
    "                #word_pos = []\n",
    "            else:\n",
    "                prepos.append(tag)\n",
    "                prepos_.append(word)\n",
    "                #word_pos.append(word) \n",
    "\n",
    "    return prepos, prepos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['IN', 'NN'], [in, africa])\n",
      "(['IN', 'DT', 'NN', 'EX', 'VBZ', 'DT', 'NN'], [in, the, room, there, 's, no, shampoo])\n",
      "(['IN', 'DT', 'NN'], [in, the, room])\n",
      "(['IN', 'DT', 'NN'], [in, the, room])\n",
      "(['IN', 'NN', 'NN'], [for, tomorrow, evening])\n",
      "(['IN', 'DT', 'JJ', 'NN'], [for, the, british, museum])\n",
      "(['IN', 'DT', 'JJ', 'NN'], [for, the, british, museum])\n",
      "(['IN', 'DT', 'JJ', 'NN'], [for, the, british, museum])\n",
      "(['IN', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NN'], [for,  , *, *, *,   , week])\n",
      "(['IN', 'JJ'], [for, wicked])\n",
      "(['IN', 'JJ'], [for, wicked])\n",
      "(['IN', 'NN'], [from, turkey])\n",
      "(['IN', 'DT', 'NN', 'VBZ'], [in, the, room, is])\n",
      "(['IN', 'DT', 'NN', 'VBZ', 'RB', 'DT', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NN'], [in, the, room, is, n't, a,   , *, *, *,  , hairdryer])\n",
      "(['IN', 'CD', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NFP', 'NFP', 'NFP'], [at, four,  , *, *, *,  , *, *, *])\n",
      "(['IN', 'DT', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NN'], [for, the,   , *, *, *,  , museum])\n",
      "(['IN', 'DT', 'NN'], [in, the, middle])\n",
      "(['IN', 'CD', 'JJ', 'NN'], [for, three, musical, ticket])\n",
      "(['IN', 'VBG', 'SP', 'NFP', 'NFP', 'NFP'], [to, notting,   , *, *, *])\n",
      "(['IN', 'NN', 'NN'], [to, nothing, hill])\n",
      "(['IN', 'VBG', 'NN'], [to, notting, hill])\n",
      "(['IN', 'VBG', 'NN'], [to, notting, hill])\n",
      "(['IN', 'DT', 'NN'], [at, the, bill])\n",
      "(['IN', 'VBG', 'NN'], [to, notting, hill])\n",
      "(['IN', 'TO', 'VB', 'DT', 'SP', 'NN'], [like, to, buy, a,   , shampoo])\n",
      "(['IN', 'DT', 'RB', 'DT', 'SP', 'TO', 'VB', 'NN', 'NN'], [for, the, piccadilly, a,       , to, leave, history, museum])\n",
      "(['IN', 'DT', 'JJ', 'NN', 'VBZ', 'EX', 'VBZ', 'EX'], [for, the, natural, italy, is, there, is, there])\n",
      "(['IN', 'DT', 'NN'], [in, the, back])\n",
      "(['IN', 'DT', 'NN'], [to, the, hairdresser])\n",
      "(['IN', 'NN', 'NN'], [by, credit, card])\n",
      "(['IN', 'NN', 'NN'], [with, credit, card])\n",
      "(['IN', 'NN', 'NN'], [by, credit, card])\n",
      "(['IN', 'NN', 'NN'], [by, credit, card])\n",
      "(['IN', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NN', 'NN'], [with,  , *, *, *,  , credit, card])\n",
      "(['IN', 'NN', 'NN'], [by, credit, card])\n",
      "(['IN', 'NN', 'NN'], [by, credit, card])\n",
      "(['IN', 'NN', 'NN'], [by, credit, card])\n",
      "(['IN', 'NN', 'NN'], [by, credit, card])\n",
      "(['IN', 'NN', 'NN'], [by, credit, card])\n",
      "(['IN', 'NN', 'NN'], [with, credit, card])\n",
      "(['IN', 'NN', 'NN'], [with, credit, card])\n",
      "(['IN', 'DT', 'NN', 'NN'], [with, the, credit, card])\n",
      "(['IN', 'NN', 'NN'], [with, credit, card])\n",
      "(['IN', 'NN', 'NN'], [with, credit, card])\n",
      "(['IN', 'NN', 'NN'], [with, credit, card])\n",
      "(['IN', 'NN', 'NN'], [by, credit, card])\n",
      "(['IN', 'NN', 'NN'], [with, credit, card])\n",
      "(['IN', 'NN', 'NN'], [with, credit, card])\n",
      "(['IN', 'NN', 'NN'], [with, credit, card])\n",
      "(['IN', 'DT', 'JJ', 'NN'], [for, the, london, eye])\n",
      "(['IN', 'DT', 'JJ', 'NN'], [for, the, london, eye])\n",
      "(['IN', 'DT', 'NN', 'NN'], [for, the, rhubarb, pie])\n",
      "(['IN', 'DT', 'NN', 'DT'], [for, the, london, a])\n",
      "(['IN', 'IN', 'NN', 'NNS'], [for, to, london, nights])\n",
      "(['IN', 'DT', 'NN', 'UH'], [for, the, london, please])\n",
      "(['IN', 'NN', 'VBZ', 'JJ'], [of, germany, is, berlin])\n",
      "(['IN', 'NN', 'VBZ', 'JJ'], [of, germany, is, berlin])\n",
      "(['IN'], [to])\n",
      "(['IN', 'DT', 'NN', 'NN'], [to, the, dessert, card])\n",
      "(['IN', 'NN', 'NN'], [for, wednesday, night])\n",
      "(['IN', 'NN', 'VBZ', 'UH'], [of, austria, is, please])\n",
      "(['IN', 'NN', 'VBZ', 'JJ'], [of, austria, is, wien])\n",
      "(['IN', 'NN', 'NN'], [at, friday, night])\n",
      "(['IN', 'NN', 'NN', 'PRP', 'SP', 'MD', 'PRP', 'VB', 'DT', 'NN', 'IN', 'NN', 'NN'], [for, friday, night, i,   , can, i, have, a, ticket, for, friday, night])\n",
      "(['IN', 'NN', 'NN'], [for, starlight, express])\n",
      "(['IN', 'NN', 'NN'], [for, starlight, express])\n",
      "(['IN', 'NN', 'NN'], [for, starlight, express])\n",
      "(['IN', 'NN', 'NN'], [on, friday, morning])\n",
      "(['IN', 'NN'], [from, england])\n",
      "(['IN', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'VB', 'NN'], [to,  , *, *, *,   , pay, visa])\n",
      "(['IN', 'NN'], [with, visa])\n",
      "(['IN', 'NN'], [with, visa])\n",
      "(['IN', 'NN'], [with, visa])\n",
      "(['IN', 'NN'], [with, visa])\n",
      "(['IN', 'NN'], [with, visa])\n",
      "(['IN', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NN'], [with,  , *, *, *,  , visa])\n",
      "(['IN', 'NN'], [by, visa])\n",
      "(['IN', 'NN'], [by, visa])\n",
      "(['IN', 'JJ', 'NN'], [with, green, park])\n",
      "(['IN', 'NN'], [with, visa])\n",
      "(['IN', 'NN'], [with, visa])\n",
      "(['IN', 'NN', 'NN'], [with, visa, card])\n",
      "(['IN', 'NN'], [with, visa])\n",
      "(['IN', 'NN'], [with, visa])\n",
      "(['IN', 'NN', 'NN'], [with, visa, visa])\n",
      "(['IN', 'DT', 'NN'], [to, the, gym])\n",
      "(['IN', 'RB', 'NN'], [from, piccadilly, circus])\n",
      "(['IN', 'DT', 'NN', 'IN', 'RB', 'NN'], [like, a, ticket, to, piccadilly, circus])\n",
      "(['IN', 'RB', 'NN'], [to, piccadilly, circus])\n",
      "(['IN', 'DT', 'NN', 'NN'], [to, the, piccadilly, circus])\n",
      "(['IN', 'RB', 'NN'], [at, billy, elliot])\n",
      "(['IN', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NN'], [to,      , *, *, *,      , italy])\n",
      "(['IN', 'DT', 'NN', 'UH'], [for, the, mastercard, please])\n",
      "(['IN', 'PRP', 'SP', 'NN', 'NN'], [for, i,    , hotel, bar])\n",
      "(['IN', 'DT', 'JJ', 'NN'], [for, the, national, gallery])\n",
      "(['IN', 'DT', 'JJ', 'NN'], [for, the, national, gallery])\n",
      "(['IN', 'DT', 'JJ', 'NN'], [for, the, national, gallery])\n",
      "(['IN', 'VB'], [to, london])\n",
      "(['IN', 'VB'], [to, london])\n",
      "(['IN', 'VB'], [to, london])\n",
      "(['IN', 'NNS'], [for, nights])\n",
      "(['IN', 'NN', 'NN'], [for, tuesday, evening])\n",
      "(['IN', 'CD', 'NNS'], [for, two, nights])\n",
      "(['IN', 'CD', 'NNS'], [for, two, nights])\n",
      "(['IN', 'NN'], [of, france])\n",
      "(['IN', 'CD', 'NNS'], [for, two, nights])\n",
      "(['IN', 'CD', 'NNS'], [for, two, nights])\n",
      "(['IN', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NN'], [for,  , *, *, *,  , tomorrow])\n",
      "(['IN', 'CD', 'NNS'], [for, two, nights])\n",
      "(['IN', 'PRP$', 'NN', 'NN'], [with, my, post, card])\n",
      "(['IN', 'IN', 'NN', 'NN'], [with, by, post, card])\n",
      "(['IN'], [with])\n",
      "(['IN', 'NN', 'NN'], [by, post, card])\n",
      "(['IN', 'NN', 'NN'], [by, post, card])\n",
      "(['IN', 'NN', 'NN'], [with, credit, card])\n",
      "(['IN', 'NN', 'NN'], [by, post, card])\n",
      "(['IN', 'NN', 'NN'], [by, master, card])\n",
      "(['IN', 'NN', 'NN'], [with, post, card])\n",
      "(['IN', 'NN', 'NN'], [with, post, card])\n",
      "(['IN', 'NN', 'NN'], [with, post, card])\n",
      "(['IN', 'NN', 'NN'], [by, post, card])\n",
      "(['IN', 'DT', 'NN', 'SP'], [for, the, room,  ])\n",
      "(['IN'], [near])\n",
      "(['IN', 'NN', 'NN'], [for, mamma, mia])\n",
      "(['IN', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'CD', 'NNS'], [for,   , *, *, *,  , two, tickets])\n",
      "(['IN', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NN'], [for,  , *, *, *,  , king])\n",
      "(['IN', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NN', 'IN', 'NN'], [for,  , *, *, *,  , king, of, lion])\n",
      "(['IN', 'DT', 'NN', 'NN'], [for, the, lion, king])\n",
      "(['IN', 'JJ', 'NN'], [on, sunday, afternoon])\n",
      "(['IN', 'NN', 'NN'], [with, credit, card])\n",
      "(['IN', 'NN', 'NN'], [with, credit, card])\n",
      "(['IN', 'NN', 'NN'], [with, credit, card])\n",
      "(['IN', 'NN', 'NN'], [for, wednesday, evening])\n",
      "(['IN', 'NN', 'NN'], [for, wednesday, night])\n",
      "(['IN', 'NN', 'VBN', 'NN'], [of, dessert, mashed, potato])\n",
      "(['IN', 'CD', 'NNS'], [for, six, nights])\n",
      "(['IN', 'CD', 'NNS'], [for, six, nights])\n",
      "(['IN', 'CD', 'NN'], [for, two, room])\n",
      "(['IN', 'CD', 'NNS'], [for, six, nights])\n",
      "(['IN', 'CD', 'NNS'], [for, seven, nights])\n",
      "(['IN', 'CD', 'NNS'], [for, six, nights])\n",
      "(['IN', 'CD', 'NNS'], [for, six, nights])\n",
      "(['IN', 'CD', 'NNS'], [for, six, nights])\n",
      "(['IN', 'DT', 'VBZ', 'DT', 'NN'], [for, this, is, the, circus])\n",
      "(['IN', 'DT', 'NN', 'NN'], [for, the, science, museum])\n",
      "(['IN', 'DT', 'NN', 'NN'], [for, the, science, museum])\n",
      "(['IN', 'NN'], [from, england])\n",
      "(['IN', 'NN'], [from, england])\n",
      "(['IN', 'NN'], [from, england])\n",
      "(['IN', 'JJ', 'NN'], [to, green, park])\n",
      "(['IN', 'JJ', 'NN'], [to, green, park])\n",
      "(['IN', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'JJ', 'NN'], [to,  , *, *, *,  , green, card])\n",
      "(['IN', 'NN', 'NN'], [for, thursday, night])\n",
      "(['IN', 'NN', 'NN'], [at, tuesday, evening])\n",
      "(['IN', 'JJ'], [for, wicked])\n",
      "(['IN', 'JJ'], [from, portugal])\n",
      "(['IN', 'VBG', 'NN'], [to, notting, hill])\n",
      "(['IN', 'NN', 'NN'], [for, mamma, mia])\n",
      "(['IN', 'NN', 'NN'], [for, mamma, mia])\n",
      "(['IN', 'VBP', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NNS', 'IN', 'NN', 'NN'], [that, want,  , *, *, *,  , tickets, for, mamma, mia])\n",
      "(['IN', 'JJ', 'NN'], [on, friday, night])\n",
      "(['IN', 'DT', 'SP', 'NN'], [with, a,   , sweatshirt])\n",
      "(['IN', 'DT', 'NN', 'NN'], [at, the, silver, level])\n",
      "(['IN', 'CD', 'NN'], [for, four, hotel])\n",
      "(['IN', 'NN'], [in, europe])\n",
      "(['IN', 'DT', 'NNS', 'IN', 'NN'], [like, the, houses, of, parliament])\n",
      "(['IN', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NN', 'NN'], [at,  , *, *, *,  , saturday, evening])\n",
      "(['IN', 'NN'], [for, wednesday])\n",
      "(['IN', 'CD', 'JJ', 'NN'], [for, five, green, park])\n",
      "(['IN', 'DT', 'PRP', 'SP', 'VBP', 'DT', 'SP', 'JJ', 'NN', 'IN', 'WRB', 'VBP', 'EX', 'DT', 'SP', 'IN', 'DT', 'SP', 'NN', 'IN', 'NN', 'NN', 'NN'], [for, the, i,   , have, a,   , double, room, for, where, are, there, a,   , like, a,    , post, by, post, hyde, park])\n",
      "(['IN', 'UH', 'NN', 'IN', 'NN', 'NN', 'NN'], [near, uh, water, by, credit, card, card])\n",
      "(['IN', 'VBG', 'IN', 'NN', 'NN'], [with, going, to, hyde, park])\n",
      "(['IN', 'NN', 'NN'], [to, hyde, park])\n",
      "(['IN', 'DT', 'JJ'], [for, the, musical])\n",
      "(['IN', 'DT', 'JJ'], [for, this, musical])\n",
      "(['IN', 'DT', 'JJ'], [for, this, musical])\n",
      "(['IN', 'DT', 'JJ'], [for, this, musical])\n",
      "(['IN', 'DT', 'JJ'], [for, this, musical])\n",
      "(['IN', 'NN', 'NN'], [on, tuesday, evening])\n",
      "(['IN', 'NN', 'NN'], [at, tuesday, night])\n",
      "(['IN', 'DT', 'NN', 'NN'], [near, the, tower, bridge])\n",
      "(['IN', 'CD', 'NNS'], [for, three, nights])\n",
      "(['IN', 'CD', 'NNS'], [for, three, nights])\n",
      "(['IN', 'CD', 'NNS'], [for, three, nights])\n",
      "(['IN', 'CD', 'NNS'], [for, three, nights])\n",
      "(['IN', 'CD', 'NNS'], [for, three, nights])\n",
      "(['IN', 'CD', 'NNS'], [for, three, nights])\n",
      "(['IN', 'CD', 'NNS'], [for, three, nights])\n",
      "(['IN', 'CD', 'NNS'], [for, four, nights])\n",
      "(['IN', 'CD', 'NNS', 'VBZ', 'PRP', 'DT', 'SP', 'NN', 'VBP', 'CD', 'DT', 'SP', 'PRP', 'VBP', 'DT', 'NN', 'IN', 'CD', 'NNS'], [for, three, nights, is, it, a,   , hotel, have, four, a,   , i, have, a, room, for, three, nights])\n",
      "(['IN', 'NN'], [from, ireland])\n",
      "(['IN', 'NN'], [by, post])\n",
      "(['IN', 'NNS'], [with, dollars])\n",
      "(['IN', 'NNS'], [by, dollars])\n",
      "(['IN', 'NN'], [for, tonight])\n",
      "(['IN', 'NN', 'TO', 'VB', 'SP'], [for, madame, to, go,   ])\n",
      "(['IN', 'DT', 'NN', 'IN', 'DT', 'NN'], [for, the, phantom, of, the, opera])\n",
      "(['IN', 'NN', 'NN'], [for, monday, evening])\n",
      "(['IN', 'NN', 'VBZ', 'JJ'], [of, france, is, paris])\n",
      "(['IN', 'VBZ', 'EX', 'DT', 'SP', 'IN', 'DT', 'SP', 'NN'], [for, is, there, a,   , like, a,       , shirt])\n",
      "(['IN', 'DT', 'NN'], [for, the, zoo])\n",
      "(['IN', 'DT', 'NN', 'SP'], [for, the, zoo,    ])\n",
      "(['IN', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'DT', 'NN'], [of,    , *, *, *,     , a, market])\n",
      "(['IN', 'NNP'], [from, austria])\n",
      "(['IN', 'NN'], [from, australia])\n",
      "(['IN', 'NN', 'NN'], [from, tower, bridge])\n",
      "(['IN', 'NNP'], [from, austria])\n",
      "(['IN', 'NNP'], [from, austria])\n",
      "(['IN', 'NN'], [from, australia])\n",
      "(['IN', 'NN'], [from, australia])\n",
      "(['IN'], [in])\n",
      "(['IN', 'DT'], [in, the])\n",
      "(['IN', 'DT', 'JJ', 'NN'], [in, the, sixth, row])\n",
      "(['IN', 'DT', 'JJ', 'NN'], [in, the, second, row])\n",
      "(['IN', 'NN'], [on, sunday])\n",
      "(['IN', 'NN'], [for, london])\n",
      "(['IN', 'NN'], [at, sunday])\n",
      "(['IN', 'IN', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NN', 'IN', 'NN'], [near, to,  , *, *, *,  , bank, of, england])\n",
      "(['IN', 'NN', 'VBZ', 'IN', 'IN', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NN', 'IN', 'NN'], [of, austria, is, near, to,  , *, *, *,  , bank, of, england])\n",
      "(['IN'], [for])\n",
      "(['IN'], [for])\n",
      "(['IN', 'CD', 'NN'], [for, two, person])\n",
      "(['IN', 'JJ'], [for, wicked])\n",
      "(['IN', 'JJ'], [for, wicked])\n",
      "(['IN', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NN', 'PRP'], [for,  , *, *, *,  , monday, you])\n",
      "(['IN', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NN', 'PRP'], [for,  , *, *, *,  , monday, you])\n",
      "(['IN', 'NN', 'VBZ', 'NN'], [of, portugal, is, lisbon])\n",
      "(['IN', 'CD', 'NN', 'NN', 'SP', 'NN'], [at, ten, o'clock, p,    , m])\n",
      "(['IN', 'DT', 'NN'], [of, the, day])\n",
      "(['IN', 'DT'], [for, the])\n",
      "(['IN', 'NN', 'NNS'], [for, morning, nights])\n",
      "(['IN', 'NN', 'NN'], [for, tomorrow, night])\n",
      "(['IN', 'NN'], [from, canada])\n",
      "(['IN', 'JJ', 'NN', 'VBP', 'SP'], [on, free, day, am,  ])\n",
      "(['IN', 'NN', 'SP', 'NFP', 'NFP', 'NFP'], [at, friday,   , *, *, *])\n",
      "(['IN', 'JJ', 'NN', 'NNS'], [on, free, day, nights])\n",
      "(['IN', 'CD', 'NNS'], [for, four, nights])\n",
      "(['IN', 'CD', 'NNS'], [for, four, nights])\n",
      "(['IN', 'CD', 'NNS', 'UH'], [for, four, nights, please])\n",
      "(['IN', 'NNS', 'VBP'], [like, tickets, please])\n",
      "(['IN', 'CD', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NNS'], [for, four,    , *, *, *,    , tickets])\n",
      "(['IN', 'CD', 'NNS', '.', 'SP', 'NN'], [at, six, p._m, .,  , tomorrow])\n",
      "(['IN', 'NN', 'IN', 'NN'], [near, bank, of, england])\n",
      "(['IN', 'NN'], [of, england])\n",
      "(['IN', 'CD', 'NNS', 'IN', 'VB'], [at, five, tickets, to, london])\n",
      "(['IN', 'VB'], [to, london])\n",
      "(['IN', 'CD', 'NNS'], [for, one, nights])\n",
      "(['IN', 'CD', 'NN'], [for, one, week])\n",
      "(['IN', 'VBP', 'DT', 'SP', 'NN'], [for, want, a,   , suite])\n",
      "(['IN', 'CD', 'NN'], [for, one, week])\n",
      "(['IN', 'CD', 'NN'], [for, one, room])\n",
      "(['IN', 'NN'], [from, france])\n",
      "(['IN', 'VB'], [to, london])\n",
      "(['IN', 'VB'], [to, london])\n",
      "(['IN', 'VB'], [to, london])\n",
      "(['IN', 'VB'], [to, london])\n",
      "(['IN', 'DT', 'NN'], [to, the, room])\n",
      "(['IN', 'NN', 'NN'], [for, saturday, night])\n",
      "(['IN', 'CD', 'SP'], [at, nine,   ])\n",
      "(['IN', 'VBP', 'DT', 'SP', 'NN', 'SP'], [for, have, a,      , room,   ])\n",
      "(['IN', 'TO', 'VB'], [like, to, london])\n",
      "(['IN', 'DT', 'NN', 'NN'], [for, the, silver, level])\n",
      "(['IN', 'DT', 'NN', 'NN'], [of, the, silver, level])\n",
      "(['IN', 'DT', 'NN', 'NN'], [at, the, silver, level])\n",
      "(['IN', 'DT', 'NN', 'NN'], [for, the, silver, level])\n",
      "(['IN', 'CD', 'NNS'], [for, seven, nights])\n",
      "(['IN', 'PRP$', 'NN'], [for, my, pass])\n",
      "(['IN', 'CD', 'NNS'], [for, seven, nights])\n",
      "(['IN', 'CD', 'NNS'], [for, five, nights])\n",
      "(['IN', 'DT', 'NN', 'IN', 'CD', 'NNS'], [for, the, room, for, five, nights])\n",
      "(['IN', 'CD', 'NNS'], [for, five, nights])\n",
      "(['IN', 'CD', 'NNS'], [for, five, nights])\n",
      "(['IN', 'CD', 'NNS'], [for, five, nights])\n",
      "(['IN', 'DT', 'JJ', 'NN', 'NN', 'SP', 'NFP', 'NFP', 'NFP'], [for, the, natural, history, museum,    , *, *, *])\n",
      "(['IN', 'DT', 'JJ', 'NN'], [for, the, natural, museum])\n",
      "(['IN', 'VB'], [to, london])\n",
      "(['IN', 'VB'], [to, london])\n",
      "(['IN', 'NN'], [for, london])\n",
      "(['IN', 'VB'], [to, london])\n",
      "(['IN', 'DT'], [for, the])\n",
      "(['IN', 'VB'], [to, london])\n",
      "(['IN', 'NN', 'NN'], [for, monday, night])\n",
      "(['IN', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'IN', 'NN', 'NN'], [to,  , *, *, *,  , for, monday, night])\n",
      "(['IN', 'NNS'], [for, trousers])\n",
      "(['IN', 'NNS'], [for, trousers])\n",
      "(['IN', 'VBZ', 'JJ'], [for, is, nick])\n",
      "(['IN', 'DT', 'JJ', 'NN'], [in, the, fourth, row])\n",
      "(['IN', 'DT', 'JJ', 'NN'], [in, the, fourth, row])\n",
      "(['IN', 'CD', 'NNS'], [for, four, nights])\n",
      "(['IN', 'VB'], [to, london])\n",
      "(['IN', 'VB'], [to, london])\n",
      "(['IN', 'VB'], [to, london])\n",
      "(['IN'], [to])\n",
      "(['IN', 'VB'], [to, london])\n",
      "(['IN', 'VB'], [to, london])\n",
      "(['IN', 'NN', 'NN'], [on, wednesday, evening])\n",
      "(['IN', 'NN', 'NN'], [at, wednesday, night])\n",
      "(['IN', 'NN', 'NN'], [at, wednesday, evening])\n",
      "(['IN', 'NN', 'NN'], [at, wednesday, night])\n",
      "(['IN', 'JJ', 'NN'], [from, switzerland, switzerland])\n",
      "(['IN', 'NN'], [from, switzerland])\n",
      "(['IN', 'PRP', 'SP', 'VBP', 'IN', 'NNP', 'DT', 'NN'], [for, i,   , am, on, saturday, the, supermarket])\n",
      "(['IN', 'NN', 'NN'], [for, dessert, card])\n",
      "(['IN', 'NN'], [from, spain])\n",
      "(['IN', 'NN'], [from, spain])\n",
      "(['IN', 'NN'], [from, spain])\n",
      "(['IN', 'NN'], [from, france])\n",
      "(['IN', 'NN'], [from, france])\n",
      "(['IN', 'PRP$', 'NN', 'VBZ', 'NN'], [for, my, name, is, museum])\n",
      "(['IN', 'DT', 'JJ'], [in, the, front])\n",
      "(['IN', 'DT', 'NN'], [in, the, room])\n",
      "(['IN', 'DT', 'JJ'], [in, the, front])\n",
      "(['IN', 'DT', 'JJ', 'NN'], [for, the, first, row])\n",
      "(['IN', 'DT', 'JJ', 'NN'], [in, the, first, row])\n",
      "(['IN', 'VB'], [to, london])\n",
      "(['IN'], [with])\n",
      "(['IN', 'NN', 'NN'], [for, wednesday, evening])\n",
      "(['IN', 'NN', 'NN'], [for, tuesday, evening])\n",
      "(['IN', 'NN', 'VBZ', 'VBN'], [of, italy, is, rome])\n",
      "(['IN', 'DT', 'NN', 'IN', 'NN'], [of, the, room, for, tomorrow])\n",
      "(['IN', 'CD', 'NN', 'NN'], [at, eight, o'clock, tomorrow])\n",
      "(['IN', 'NN'], [by, card])\n",
      "(['IN', 'NN'], [by, card])\n",
      "(['IN', 'NNS'], [with, pounds])\n",
      "(['IN', 'NN'], [with, bar])\n",
      "(['IN', 'NN'], [with, euro])\n",
      "(['IN', 'NNS'], [with, pounds])\n",
      "(['IN', 'NN'], [by, mastercard])\n",
      "(['IN', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NN'], [by,    , *, *, *,   , mastercard])\n",
      "(['IN', 'PRP$', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NN'], [with, my,    , *, *, *,   , mastercard])\n",
      "(['IN', 'NN'], [by, mastercard])\n",
      "(['IN', 'NN'], [with, mastercard])\n",
      "(['IN', 'NN', 'NN', 'SP'], [with, master, card,   ])\n",
      "(['IN', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NN'], [by,    , *, *, *,   , mastercard])\n",
      "(['IN', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NN'], [with,    , *, *, *,   , mastercard])\n",
      "(['IN', 'NN', 'IN', 'NN', 'SP'], [with, leave, at, card,   ])\n",
      "(['IN', 'NN'], [with, mastercard])\n",
      "(['IN', 'VBZ', 'DT', 'NN'], [with, is, the, mastercard])\n",
      "(['IN', 'NN'], [with, mastercard])\n",
      "(['IN', 'DT', 'NN', 'NN'], [in, the, eighth, row])\n",
      "(['IN', 'DT', 'NN', 'NN'], [in, the, eighth, row])\n",
      "(['IN', 'RB', 'NN'], [for, billy, elliot])\n",
      "(['IN', 'NN', 'SP'], [from, france,  ])\n",
      "(['IN', 'DT', 'NN', 'NN', 'SP'], [for, the, hotel, bar,   ])\n",
      "(['IN', 'PRP$', 'NN', 'NN'], [at, my, passport, tomorrow])\n",
      "(['IN', 'NNS'], [at, euros])\n",
      "(['IN', 'CD', 'NN', 'NN'], [at, twelve, o'clock, tomorrow])\n",
      "(['IN', 'NN'], [from, america])\n",
      "(['IN', 'NN'], [from, america])\n",
      "(['IN', 'DT', 'JJ', 'NN'], [in, the, fifth, row])\n",
      "(['IN', 'DT', 'JJ', 'NN'], [in, the, fifth, row])\n",
      "(['IN', 'DT', 'JJ', 'NN'], [in, the, fifth, row])\n",
      "(['IN', 'RB', 'JJ', 'NN'], [to, just, elder, square])\n",
      "(['IN', 'DT', 'NN', 'NN'], [to, the, trou, bread])\n",
      "(['IN'], [through])\n",
      "(['IN', 'NN', 'NN'], [for, sunday, night])\n",
      "(['IN', 'PRP$', 'NN', 'NN', 'NN'], [like, my, sunday, roast, medium])\n",
      "(['IN', 'DT', 'NN', 'VBZ', 'VBN'], [of, the, swiss, is, rome])\n",
      "(['IN', 'NN', 'VBZ', 'JJ'], [of, switzerland, is, rome])\n",
      "(['IN', 'NN'], [for, tomorrow])\n",
      "(['IN', 'CD', 'TO', 'VB', 'NN'], [for, two, to, piccadilly, circus])\n",
      "(['IN', 'JJ', 'NNS'], [with, swiss, francs])\n",
      "(['IN', 'NN', 'IN', 'NN', 'NN'], [with, master, with, master, card])\n",
      "(['IN', 'NN'], [from, france])\n",
      "(['IN', 'NN'], [from, france])\n",
      "(['IN', 'JJ', 'NNS'], [with, swiss, francs])\n",
      "(['IN', 'JJ', 'NNS'], [with, swiss, francs])\n",
      "(['IN', 'JJ'], [from, italy])\n",
      "(['IN', 'NN'], [from, italia])\n",
      "(['IN', 'NN'], [from, switzerland])\n",
      "(['IN', 'NN'], [from, england])\n",
      "(['IN', 'PRP'], [from, tu])\n",
      "(['IN', 'NN'], [into, holiday])\n",
      "(['IN', 'NN'], [into, holiday])\n",
      "(['IN', 'NN'], [into, holiday])\n",
      "(['IN', 'NNS'], [on, holidays])\n",
      "(['IN', 'NNS'], [on, holidays])\n",
      "(['IN', 'SP', 'NFP', 'NFP', 'NFP', 'SP', 'NN'], [on,  , *, *, *,  , holiday])\n",
      "(['IN', 'NN'], [from, scotland])\n",
      "(['IN', 'NN'], [from, scotland])\n",
      "(['IN'], [for])\n",
      "(['IN', 'NN'], [from, germany])\n",
      "(['IN', 'NN'], [from, germany])\n",
      "(['IN', 'NN'], [from, germany])\n",
      "(['IN', 'JJ'], [from, german])\n",
      "(['IN', 'NNP', 'VBZ', 'NN'], [from, germany, is, rome])\n",
      "(['IN', 'NN'], [from, france])\n",
      "(['IN', 'NNS'], [with, euros])\n"
     ]
    }
   ],
   "source": [
    "sent = \"can i have a hotel room for one nights\"\n",
    "pre_chunks = []\n",
    "for item in prompt_test_map:\n",
    "    for res in prompt_test_map[item]:\n",
    "        pre = extract_prepo(res['transcript'])\n",
    "\n",
    "        if len(pre[0]) >0:\n",
    "            pre_chunks.append(\" \".join(pre[0]))\n",
    "            print(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IN',\n",
       " 'IN CD JJ NN',\n",
       " 'IN CD NN',\n",
       " 'IN CD NN NN',\n",
       " 'IN CD NN NN SP NN',\n",
       " 'IN CD NNS',\n",
       " 'IN CD NNS . SP NN',\n",
       " 'IN CD NNS IN VB',\n",
       " 'IN CD NNS UH',\n",
       " 'IN CD NNS VBZ PRP DT SP NN VBP CD DT SP PRP VBP DT NN IN CD NNS',\n",
       " 'IN CD SP',\n",
       " 'IN CD SP NFP NFP NFP SP NFP NFP NFP',\n",
       " 'IN CD SP NFP NFP NFP SP NNS',\n",
       " 'IN CD TO VB NN',\n",
       " 'IN DT',\n",
       " 'IN DT JJ',\n",
       " 'IN DT JJ NN',\n",
       " 'IN DT JJ NN NN SP NFP NFP NFP',\n",
       " 'IN DT JJ NN VBZ EX VBZ EX',\n",
       " 'IN DT NN',\n",
       " 'IN DT NN DT',\n",
       " 'IN DT NN EX VBZ DT NN',\n",
       " 'IN DT NN IN CD NNS',\n",
       " 'IN DT NN IN DT NN',\n",
       " 'IN DT NN IN NN',\n",
       " 'IN DT NN IN RB NN',\n",
       " 'IN DT NN NN',\n",
       " 'IN DT NN NN SP',\n",
       " 'IN DT NN SP',\n",
       " 'IN DT NN UH',\n",
       " 'IN DT NN VBZ',\n",
       " 'IN DT NN VBZ RB DT SP NFP NFP NFP SP NN',\n",
       " 'IN DT NN VBZ VBN',\n",
       " 'IN DT NNS IN NN',\n",
       " 'IN DT PRP SP VBP DT SP JJ NN IN WRB VBP EX DT SP IN DT SP NN IN NN NN NN',\n",
       " 'IN DT RB DT SP TO VB NN NN',\n",
       " 'IN DT SP NFP NFP NFP SP NN',\n",
       " 'IN DT SP NN',\n",
       " 'IN DT VBZ DT NN',\n",
       " 'IN IN NN NN',\n",
       " 'IN IN NN NNS',\n",
       " 'IN IN SP NFP NFP NFP SP NN IN NN',\n",
       " 'IN JJ',\n",
       " 'IN JJ NN',\n",
       " 'IN JJ NN NNS',\n",
       " 'IN JJ NN VBP SP',\n",
       " 'IN JJ NNS',\n",
       " 'IN NN',\n",
       " 'IN NN IN NN',\n",
       " 'IN NN IN NN NN',\n",
       " 'IN NN IN NN SP',\n",
       " 'IN NN NN',\n",
       " 'IN NN NN PRP SP MD PRP VB DT NN IN NN NN',\n",
       " 'IN NN NN SP',\n",
       " 'IN NN NNS',\n",
       " 'IN NN SP',\n",
       " 'IN NN SP NFP NFP NFP',\n",
       " 'IN NN TO VB SP',\n",
       " 'IN NN VBN NN',\n",
       " 'IN NN VBZ IN IN SP NFP NFP NFP SP NN IN NN',\n",
       " 'IN NN VBZ JJ',\n",
       " 'IN NN VBZ NN',\n",
       " 'IN NN VBZ UH',\n",
       " 'IN NN VBZ VBN',\n",
       " 'IN NNP',\n",
       " 'IN NNP VBZ NN',\n",
       " 'IN NNS',\n",
       " 'IN NNS VBP',\n",
       " 'IN PRP',\n",
       " 'IN PRP SP NN NN',\n",
       " 'IN PRP SP VBP IN NNP DT NN',\n",
       " 'IN PRP$ NN',\n",
       " 'IN PRP$ NN NN',\n",
       " 'IN PRP$ NN NN NN',\n",
       " 'IN PRP$ NN VBZ NN',\n",
       " 'IN PRP$ SP NFP NFP NFP SP NN',\n",
       " 'IN RB JJ NN',\n",
       " 'IN RB NN',\n",
       " 'IN SP NFP NFP NFP SP CD NNS',\n",
       " 'IN SP NFP NFP NFP SP DT NN',\n",
       " 'IN SP NFP NFP NFP SP IN NN NN',\n",
       " 'IN SP NFP NFP NFP SP JJ NN',\n",
       " 'IN SP NFP NFP NFP SP NN',\n",
       " 'IN SP NFP NFP NFP SP NN IN NN',\n",
       " 'IN SP NFP NFP NFP SP NN NN',\n",
       " 'IN SP NFP NFP NFP SP NN PRP',\n",
       " 'IN SP NFP NFP NFP SP VB NN',\n",
       " 'IN TO VB',\n",
       " 'IN TO VB DT SP NN',\n",
       " 'IN UH NN IN NN NN NN',\n",
       " 'IN VB',\n",
       " 'IN VBG IN NN NN',\n",
       " 'IN VBG NN',\n",
       " 'IN VBG SP NFP NFP NFP',\n",
       " 'IN VBP DT SP NN',\n",
       " 'IN VBP DT SP NN SP',\n",
       " 'IN VBP SP NFP NFP NFP SP NNS IN NN NN',\n",
       " 'IN VBZ DT NN',\n",
       " 'IN VBZ EX DT SP IN DT SP NN',\n",
       " 'IN VBZ JJ'}"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pre_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
